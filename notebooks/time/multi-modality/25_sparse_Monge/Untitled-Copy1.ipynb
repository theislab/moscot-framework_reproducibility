{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ee165ab-b11c-4d6c-a1d6-e016f4bee33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "jax.config.update('jax_platform_name', 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f42a722-6ec6-4f69-849e-cfdd15e9ae50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/dominik.klein/mambaforge/envs/moscot_rev_new/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import muon\n",
    "import ott\n",
    "import functools\n",
    "import logging\n",
    "import typing as t\n",
    "\n",
    "import anndata as ad\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "import scipy.stats as ss\n",
    "from ott.geometry import costs, geometry, pointcloud\n",
    "from ott.problems.linear import linear_problem, potentials\n",
    "from ott.solvers.linear import sinkhorn\n",
    "from ott.tools import sinkhorn_divergence\n",
    "from sklearn import metrics, model_selection\n",
    "from ott.geometry import costs as sparse_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbc69ae6-9d68-4339-9edf-6ebfca32813f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/dominik.klein/mambaforge/envs/moscot_rev_new/lib/python3.12/site-packages/anndata/_core/anndata.py:522: FutureWarning: The dtype argument is deprecated and will be removed in late 2024.\n",
      "  warnings.warn(\n",
      "/home/icb/dominik.klein/mambaforge/envs/moscot_rev_new/lib/python3.12/site-packages/anndata/_core/anndata.py:522: FutureWarning: The dtype argument is deprecated and will be removed in late 2024.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mudata = muon.read(\"/lustre/groups/ml01/workspace/moscot_paper/pancreas_revision/mudata_with_annotation_all.h5mu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de83ea41-336f-478e-8653-ba5b1a915e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "endocrine_celltypes = [\n",
    "    \"Ngn3 low\",\n",
    "    \"Ngn3 high\",\n",
    "    \"Ngn3 high cycling\",\n",
    "    \"Fev+\",\n",
    "    \"Fev+ Alpha\",\n",
    "    \"Fev+ Beta\",\n",
    "    \"Fev+ Delta\",\n",
    "    \"Eps. progenitors\",\n",
    "    \"Alpha\",\n",
    "    \"Beta\",\n",
    "    \"Delta\",\n",
    "    \"Epsilon\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77e76261-9f2c-4424-9453-e9a2e9f06da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = mudata[\"rna\"]\n",
    "adata = adata[adata.obs[\"cell_type\"].isin(endocrine_celltypes)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac82097a-5d11-4c44-9aa1-969ca8403fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1465575/440930313.py:10: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs['time'] = adata.obs.apply(adapt_time, axis=1).astype(\"category\")\n"
     ]
    }
   ],
   "source": [
    "def adapt_time(x):\n",
    "    if x[\"stage\"]==\"E14.5\":\n",
    "        return 14.5\n",
    "    if x[\"stage\"]==\"E15.5\":\n",
    "        return 15.5\n",
    "    if x[\"stage\"]==\"E16.5\":\n",
    "        return 16.5\n",
    "    raise ValueError\n",
    "\n",
    "adata.obs['time'] = adata.obs.apply(adapt_time, axis=1).astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbf17013-6ac0-4bb8-8692-97998c34d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[adata.obs[\"time\"].isin((15.5, 16.5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92de6fd5-f652-4d53-b11c-9a3c238eb251",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X = adata.layers[\"raw_counts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "754cee9f-9cc5-4f07-bbaf-7a1f245c4203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/dominik.klein/mambaforge/envs/moscot_rev_new/lib/python3.12/site-packages/scanpy/preprocessing/_normalization.py:169: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    }
   ],
   "source": [
    "sc.pp.normalize_total(adata)\n",
    "sc.pp.log1p(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cee85c69-395d-4f46-8c2c-606254f1aa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/dominik.klein/mambaforge/envs/moscot_rev_new/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:226: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  disp_grouped = df.groupby(\"mean_bin\")[\"dispersions\"]\n"
     ]
    }
   ],
   "source": [
    "sc.pp.highly_variable_genes(adata, inplace=True, subset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1653da51-d3d6-45e4-942e-3a7accc9ceca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 6884 × 2580\n",
       "    obs: 'sample', 'name', 'stage', 'stage_num', 'int_id', 'seq_id_gex_id', 'seq_id_atac', 'reporter', 'experiment_batch', 'sequencing_batch', 'n_counts', 'log_counts', 'n_counts_rank', 'n_genes', 'log_genes', 'mt_frac', 'rp_frac', 'ambi_frac', 'final_doublets', 'final_doublets_cat', 'doublet_calls', 'batch', 'size_factors', 'leiden', 'leiden_05_rna', 'leiden_05_atac', 'leiden_1_rna', 'leiden_1_atac', 'leiden_combined', 'leiden_gex_graph', 'leiden_ATAC_graph', 'leiden_wnn_graph', 'cell_type', 'cell_type_refined', 'S_score', 'G2M_score', 'phase', 'proliferation', 'time'\n",
       "    var: 'gene_ids', 'feature_types', 'genome', 'interval', 'ambient_genes_E14_5-0', 'is_ambient_E14_5-0', 'n_counts-0', 'n_counts-1', 'ambient_genes_E15_5-1', 'is_ambient_E15_5-1', 'n_counts-2', 'ambient_genes_NVF_E15-5_Rep2-2', 'is_ambient_NVF_E15-5_Rep2-2', 'n_counts-3', 'ambient_genes_NVF_E16-5_Rep1-3', 'is_ambient_NVF_E16-5_Rep1-3', 'is_ambient', 'n_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'sct.detection_rate', 'sct.gmean', 'sct.variance', 'sct.residual_variance', 'sct.variable'\n",
       "    uns: 'cell_type_colors', 'cell_type_refined_colors', 'experiment_batch_colors', 'final_doublets_cat_colors', 'hvg', 'leiden', 'leiden_05_atac_colors', 'leiden_05_rna_colors', 'leiden_1_atac_colors', 'leiden_1_rna_colors', 'leiden_ATAC_graph_colors', 'leiden_colors', 'leiden_combined_colors', 'leiden_gex_graph_colors', 'leiden_wnn_graph_colors', 'log1p', 'neighbors', 'pca', 'sample_colors', 'umap'\n",
       "    obsm: 'X_pca', 'X_scVI', 'X_umap', 'X_umap_rna_unintegrated'\n",
       "    varm: 'PCs'\n",
       "    layers: 'X_scVI_reconstruction', 'ambiguous', 'log_raw_counts', 'matrix', 'raw_counts', 'scran_counts', 'sct_counts', 'sct_logcounts', 'sct_scale_data', 'spliced', 'unspliced'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "346806f7-3753-4299-99b0-a04811826503",
   "metadata": {},
   "outputs": [],
   "source": [
    "gex_early = adata[adata.obs[\"time\"]==15.5].X.A\n",
    "gex_late = adata[adata.obs[\"time\"]==16.5].X.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1d78116-69e4-4817-abaf-026e917a35bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=gex_early\n",
    "y=gex_late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78808a7e-91d5-46c6-8a84-6d123776b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = jax.jit(sinkhorn.Sinkhorn())\n",
    "\n",
    "\n",
    "def entropic_map(x, y, cost_fn: costs.TICost) -> jnp.ndarray:\n",
    "    geom = pointcloud.PointCloud(x, y, cost_fn=cost_fn)\n",
    "    output = solver(linear_problem.LinearProblem(geom))\n",
    "    dual_potentials = output.to_dual_potentials()\n",
    "    return dual_potentials.transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5cacd1-da2c-4581-9464-80cb1ee54133",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_l1 = entropic_map(x, y, costs.ElasticL1(scaling_reg=10.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337bf571-5177-4558-a47f-eb362c07f4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_red = x[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb71efc-8f21-46ec-ad91-10ae4caf5e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "push_forward = map_l1(x_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e25a40-5bc9-404e-823b-81ce60821b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6981d4ee-45ac-42c0-8221-886501b571f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "push_forward = map_l1(x_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2143ddfc-03c1-4542-b4bf-6e2c3c727186",
   "metadata": {},
   "outputs": [],
   "source": [
    "push_forward.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b89385e-83b5-42ee-be9b-58c173f2fd18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca956437-4682-4243-b494-f8972abbfefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sink_div = jax.jit(\n",
    "    sinkhorn_divergence.sinkhorn_divergence,\n",
    "    static_argnames=[\"geom\", \"cost_fn\", \"epsilon\", \"batch_size\"],\n",
    ")\n",
    "\n",
    "def _extract_cost_matrix(\n",
    "    x: jnp.ndarray,\n",
    "    y: jnp.ndarray,\n",
    "    cost_fn: sparse_costs.RegTICost,\n",
    "    epsilon: t.Optional[float] = None,\n",
    "    scale_cost: t.Union[t.Literal[\"mean\", \"max_cost\"], float] = 1.0,\n",
    "    batch_size: int = 4,\n",
    ") -> t.Tuple[geometry.Geometry, pointcloud.PointCloud]:\n",
    "    cost_matrix = []\n",
    "    for i in range(0, x.shape[0], batch_size):\n",
    "        tmp = jnp.array(x[i : i + batch_size])\n",
    "        tmp = pointcloud.PointCloud(tmp, y, cost_fn=cost_fn, scale_cost=1.0)\n",
    "        cost_matrix.append(tmp.cost_matrix)\n",
    "\n",
    "    cost_matrix = jnp.concatenate(cost_matrix)\n",
    "    geom = geometry.Geometry(\n",
    "        cost_matrix=cost_matrix, scale_cost=scale_cost, epsilon=epsilon\n",
    "    )\n",
    "    pc = pointcloud.PointCloud(x, y, epsilon=geom.epsilon, cost_fn=cost_fn)\n",
    "\n",
    "    assert geom.shape == (x.shape[0], y.shape[0])\n",
    "    assert geom.shape == pc.shape\n",
    "    return geom, pc\n",
    "\n",
    "\n",
    "@functools.partial(\n",
    "    jax.jit,\n",
    "    static_argnames=(\n",
    "        \"tau_a\",\n",
    "        \"tau_b\",\n",
    "        \"max_iterations\",\n",
    "        \"threshold\",\n",
    "    ),\n",
    ")\n",
    "def _solve(\n",
    "    geom: geometry.Geometry,\n",
    "    pc: t.Optional[\n",
    "        pointcloud.PointCloud\n",
    "    ] = None,  # for potentials in case of ElasticNet/GroupNorm\n",
    "    *,\n",
    "    tau_a: float = 1.0,\n",
    "    tau_b: float = 1.0,\n",
    "    **kwargs: t.Any,\n",
    ") -> t.Tuple[sinkhorn.SinkhornOutput, potentials.EntropicPotentials]:\n",
    "    prob = linear_problem.LinearProblem(geom, tau_a=tau_a, tau_b=tau_b)\n",
    "\n",
    "    out = sinkhorn.Sinkhorn(**kwargs)(prob)\n",
    "    if pc is None:\n",
    "        return out, out.to_dual_potentials()\n",
    "\n",
    "    pc_prob = linear_problem.LinearProblem(pc, tau_a=tau_a, tau_b=tau_b)\n",
    "    dp = potentials.EntropicPotentials(out.f, out.g, pc_prob)\n",
    "\n",
    "    return out, dp\n",
    "\n",
    "\n",
    "def solve(\n",
    "    ds: Dataset,\n",
    "    cost_fn: t.Union[costs.SqEuclidean, sparse_costs.RegTICost],\n",
    "    epsilon: t.Optional[float] = None,\n",
    "    batch_size: int = 4,\n",
    "    scale_cost: t.Union[t.Literal[\"mean\", \"max_cost\"], float] = 1.0,\n",
    "    tau_a: float = 1.0,\n",
    "    tau_b: float = 1.0,\n",
    "    **kwargs: t.Any,\n",
    ") -> t.Tuple[sinkhorn.SinkhornOutput, potentials.EntropicPotentials]:\n",
    "    if isinstance(cost_fn, costs.SqEuclidean):\n",
    "        geom = pointcloud.PointCloud(\n",
    "            ds.trn_x,\n",
    "            ds.trn_y,\n",
    "            cost_fn=cost_fn,\n",
    "            scale_cost=scale_cost,\n",
    "            batch_size=batch_size,\n",
    "            epsilon=epsilon,\n",
    "        )\n",
    "        out, dp = _solve(geom, None, tau_a=tau_a, tau_b=tau_b, **kwargs)\n",
    "    elif isinstance(cost_fn, sparse_costs.RegTICost):\n",
    "        geom, pc = _extract_cost_matrix(\n",
    "            ds.trn_x,\n",
    "            ds.trn_y,\n",
    "            cost_fn=cost_fn,\n",
    "            epsilon=epsilon,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "        out, dp = _solve(geom, pc, tau_a=tau_a, tau_b=tau_b, **kwargs)\n",
    "    else:\n",
    "        raise TypeError(type(cost_fn))\n",
    "\n",
    "    plt.plot(out.errors[: out.n_iters])\n",
    "    plt.title(f\"converged: {out.converged}\")\n",
    "\n",
    "    return out, dp\n",
    "\n",
    "\n",
    "def predict(\n",
    "    ds: Dataset,\n",
    "    dp: potentials.EntropicPotentials,\n",
    "    *,\n",
    "    forward: bool,\n",
    "    batch_size: int = 4,\n",
    "    nan_to_num: t.Optional[float] = 0.0,\n",
    ") -> t.Tuple[jnp.ndarray, float, float, float]:\n",
    "    data = ds.tst_x if forward else ds.tst_y\n",
    "    n = data.shape[0]\n",
    "\n",
    "    pred_trans, pred = [], []\n",
    "    for i in range(0, n, batch_size):\n",
    "        tmp = data[i : i + batch_size]\n",
    "        tmp = np.asarray(dp.transport(tmp, forward=forward))\n",
    "        if ds.is_pca:\n",
    "            pred_trans.append(tmp)\n",
    "            tmp = np.asarray(ds.upproject(tmp))\n",
    "        pred.append(tmp)\n",
    "\n",
    "    pred = np.concatenate(pred)\n",
    "    if ds.is_pca:\n",
    "        pred_trans = np.concatenate(pred_trans)\n",
    "        assert data.shape == pred_trans.shape\n",
    "        assert data.shape[0] == pred.shape[0]\n",
    "    else:\n",
    "        assert data.shape == pred.shape\n",
    "    if nan_to_num is not None:\n",
    "        pred = np.nan_to_num(pred, nan=nan_to_num, copy=False)\n",
    "\n",
    "    if ds.is_pca:\n",
    "        expected = ds.adata_tst_x.X if forward else ds.adata_tst_y.X\n",
    "        expected = expected.A if sp.issparse(expected) else expected\n",
    "        perc_close = np.sum(np.isclose(pred, expected)) / pred.size\n",
    "    else:\n",
    "        perc_close = np.sum(np.isclose(pred, data)) / pred.size\n",
    "    perc_neg = np.sum(pred < 0) / pred.size\n",
    "    min_neg = np.min(pred)\n",
    "\n",
    "    if ds.is_pca:\n",
    "        return jnp.asarray(pred), jnp.asarray(pred_trans), perc_close, perc_neg, min_neg\n",
    "\n",
    "    return jnp.asarray(pred), perc_close, perc_neg, min_neg\n",
    "\n",
    "\n",
    "def pca_metric(\n",
    "    ds: Dataset,\n",
    "    ds_pca: Dataset,\n",
    "    data_hat: jnp.ndarray,  # reduced dim data\n",
    "    data_hat_raw: jnp.ndarray,  # full dim data\n",
    "    *,\n",
    "    frac: float,\n",
    "    cost_fn: costs.CostFn,\n",
    "    batch_size: t.Optional[int],\n",
    "    forward: bool = True,\n",
    ") -> t.Tuple[float, float]:\n",
    "    assert not ds.is_pca\n",
    "    assert ds_pca.is_pca\n",
    "\n",
    "    if forward:\n",
    "        data = ds_pca.tst_y  # (n, 50)\n",
    "        data_raw = ds.tst_y  # (n, g)\n",
    "    else:\n",
    "        data = ds_pca.tst_x\n",
    "        data_raw = ds.tst_x\n",
    "\n",
    "    div = solve_sink_div(data, data_hat, frac=frac, cost_fn=costs.SqEuclidean())\n",
    "    div_raw = solve_sink_div(\n",
    "        data_raw, data_hat_raw, frac=frac, cost_fn=cost_fn, batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    return div, div_raw\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    ds: Dataset,\n",
    "    data_hat: jnp.ndarray,\n",
    "    *,\n",
    "    forward: bool,\n",
    "    cost_fn: t.Union[costs.SqEuclidean, sparse_costs.RegTICost],\n",
    "    genes: t.Optional[t.List[str]] = None,\n",
    "    epsilon: t.Optional[float] = None,\n",
    "    **kwargs: t.Any,\n",
    ") -> t.Tuple[float, float, int]:\n",
    "    data = ds.tst_y if forward else ds.tst_x\n",
    "    if genes is not None:\n",
    "        assert not ds.is_pca, \"Cannot be a PCA dataset\"\n",
    "        assert isinstance(cost_fn, costs.SqEuclidean)\n",
    "        mask = jnp.asarray(ds.adata.var_names.isin(genes))\n",
    "        n_genes = int(jnp.sum(mask))\n",
    "        data = data[:, mask]\n",
    "        data_hat = data_hat[:, mask]\n",
    "    else:\n",
    "        n_genes = data_hat.shape[1]\n",
    "\n",
    "    out_div: sinkhorn_divergence.SinkhornDivergenceOutput = sink_div(\n",
    "        pointcloud.PointCloud,\n",
    "        data_hat,\n",
    "        data,\n",
    "        epsilon=epsilon,\n",
    "        cost_fn=cost_fn,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    return np.nan, float(out_div.divergence), n_genes\n",
    "\n",
    "    # TODO(michalk8): tries to allocated `f32[2594,620,5000]`, (n, m, d)\n",
    "    geom = pointcloud.PointCloud(\n",
    "        data_hat, data, epsilon=epsilon, cost_fn=cost_fn, **kwargs\n",
    "    )\n",
    "    out_sink, _ = _solve(geom)\n",
    "\n",
    "    return float(out_sink.primal_cost), float(out_div.divergence), n_genes\n",
    "\n",
    "\n",
    "def feature_correlation(\n",
    "    ds: Dataset,\n",
    "    data_hat: jnp.ndarray,\n",
    "    *,\n",
    "    forward: bool,\n",
    ") -> t.Dict[str, np.ndarray]:\n",
    "    data = np.asarray(ds.tst_x if forward else ds.tst_y)\n",
    "    data_hat = np.asarray(data_hat)\n",
    "\n",
    "    stats = {\"pearson\": [], \"spearman\": []}\n",
    "    for i in range(data_hat.shape[1]):\n",
    "        x, y = data_hat[:, i], data[:, i]\n",
    "        stats[\"pearson\"].append(ss.pearsonr(x, y).statistic)\n",
    "        stats[\"spearman\"].append(ss.spearmanr(x, y).statistic)\n",
    "\n",
    "    stats = {k: np.asarray(v) for k, v in stats.items()}\n",
    "    return {\n",
    "        f\"{k}_{agg}\": getattr(np, \"nan\" + agg)(v)\n",
    "        for k, v in stats.items()\n",
    "        for agg in [\"mean\", \"std\"]\n",
    "    }\n",
    "\n",
    "\n",
    "def r2(\n",
    "    ds: Dataset,\n",
    "    data_hat: jnp.ndarray,\n",
    "    *,\n",
    "    forward: bool,\n",
    "    genes: t.Optional[t.List[str]],\n",
    ") -> t.Dict[str, float]:\n",
    "    if genes is None:\n",
    "        genes = ds.adata.var_names\n",
    "    mask = ds.adata.var_names.isin(genes)\n",
    "\n",
    "    if forward:\n",
    "        data = np.asarray(ds.tst_y)[:, mask]\n",
    "        other = np.asarray(ds.tst_x)[:, mask]\n",
    "    else:\n",
    "        data = np.asarray(ds.tst_x)[:, mask]\n",
    "        other = np.asarray(ds.tst_y)[:, mask]\n",
    "    data_hat = np.asarray(data_hat)[:, mask]\n",
    "\n",
    "    def compute(\n",
    "        data: jnp.ndarray, data_hat: jnp.ndarray, other: jnp.ndarray\n",
    "    ) -> t.Tuple[float, float]:\n",
    "\n",
    "        data_mean = np.mean(data, axis=0)\n",
    "        data_hat_mean = np.mean(data_hat, axis=0)\n",
    "        other_mean = np.mean(other, axis=0)\n",
    "\n",
    "        log2fc = data_mean - other_mean\n",
    "        log2fc_hat = data_hat_mean - other_mean\n",
    "\n",
    "        mean_r2 = metrics.r2_score(data_mean, data_hat_mean)\n",
    "        log2fc_r2 = metrics.r2_score(log2fc, log2fc_hat)\n",
    "        return mean_r2, log2fc_r2\n",
    "\n",
    "    mean, log2fold = compute(data, data_hat, other)\n",
    "    res = {\"mean-all-r2\": mean, \"log2fc-all-r2\": log2fold}\n",
    "    for dosage, mask in ds.dosage_mask.items():\n",
    "        if forward:\n",
    "            mean, log2fold = compute(data[mask], data_hat, other)\n",
    "        else:\n",
    "            mean, log2fold = compute(data, data_hat, other[mask])\n",
    "        res[f\"mean-{dosage}-r2\"] = mean\n",
    "        res[f\"log2fc-{dosage}-r2\"] = log2fold\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def gene_metric(\n",
    "    ds: Dataset,\n",
    "    data_hat: jnp.ndarray,\n",
    "    *,\n",
    "    forward: bool,\n",
    "    genes: t.Sequence[str],\n",
    "    p: float = 0.9,\n",
    ") -> t.Dict[str, t.Any]:\n",
    "    gt_genes = list(genes)\n",
    "    data_hat = np.array(data_hat)\n",
    "    data = np.asarray(ds.tst_x if forward else ds.tst_y)\n",
    "\n",
    "    vals = jnp.mean((data_hat - data), axis=0)  # log2fc\n",
    "    gene_ixs = np.argsort(vals)[::-1]\n",
    "    pred_genes = list(ds.adata.var_names[gene_ixs])\n",
    "\n",
    "    metric = rbo.RankingSimilarity(pred_genes, gt_genes).rbo(k=len(gt_genes), p=p)\n",
    "\n",
    "    return {\n",
    "        \"rbo\": metric,\n",
    "        \"gt_genes\": gt_genes,\n",
    "        \"scores_hat\": vals,\n",
    "        \"all_genes\": list(ds.adata.var_names),\n",
    "        \"k\": len(gt_genes),\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_epsilons(\n",
    "    ds: Dataset,\n",
    "    data_hat: jnp.ndarray,\n",
    "    cost_fn: t.Union[costs.SqEuclidean, sparse_costs.RegTICost],\n",
    "    *,\n",
    "    forward: bool,\n",
    "    fracs: t.Sequence[float],\n",
    "    batch_size: int,\n",
    "    use_train: bool = False,\n",
    ") -> t.Sequence[t.Optional[float]]:\n",
    "    if use_train:\n",
    "        data = ds.trn_y  # assumes `data_x` is `ds.trn_x`\n",
    "    else:\n",
    "        data = ds.tst_y if forward else ds.tst_x\n",
    "\n",
    "    mean = mean_cost(data_hat, data, cost_fn=cost_fn, batch_size=batch_size)\n",
    "    return [None if f <= 0 else float(f * mean) for f in fracs]\n",
    "\n",
    "\n",
    "def mean_cost(\n",
    "    x: jnp.ndarray,\n",
    "    y: jnp.ndarray,\n",
    "    *,\n",
    "    cost_fn: costs.CostFn,\n",
    "    batch_size: t.Optional[int],\n",
    ") -> float:\n",
    "    inv_mean = pointcloud.PointCloud(\n",
    "        x,\n",
    "        y,\n",
    "        cost_fn=cost_fn,\n",
    "        batch_size=batch_size,\n",
    "        scale_cost=\"mean\",\n",
    "    ).inv_scale_cost\n",
    "    return float(1.0 / inv_mean)\n",
    "\n",
    "\n",
    "def solve_sink_div(\n",
    "    data: jnp.ndarray,\n",
    "    data_hat: jnp.ndarray,\n",
    "    *,\n",
    "    frac: float,\n",
    "    cost_fn: costs.CostFn,\n",
    "    batch_size: int = 1024,\n",
    ") -> float:\n",
    "    epsilon = frac * mean_cost(\n",
    "        data,\n",
    "        data_hat,\n",
    "        cost_fn=cost_fn,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    div = sink_div(\n",
    "        pointcloud.PointCloud,\n",
    "        data,\n",
    "        data_hat,\n",
    "        cost_fn=cost_fn,\n",
    "        epsilon=epsilon,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    return float(div.divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88413fc6-a02a-4895-9643-0c06df39bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gc\n",
    "import logging\n",
    "import pathlib\n",
    "import pickle\n",
    "import time\n",
    "import typing as t\n",
    "\n",
    "import anndata as ad\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from ott.geometry import costs\n",
    "from tqdm import tqdm\n",
    "\n",
    "import data_utils as du\n",
    "import sparse_costs\n",
    "\n",
    "CONTROL = \"DMSO\"\n",
    "LOGGER = logging.getLogger()\n",
    "MEAN_COST_FRAC = 0.1\n",
    "\n",
    "\n",
    "def _compute_markers(\n",
    "    adata: ad.AnnData,\n",
    "    pert: str,\n",
    "    n_genes: t.Optional[int],\n",
    "    key_added: t.Optional[str] = None,\n",
    "    *,\n",
    "    alpha: t.Optional[float] = None,\n",
    "    log2fc_min: t.Optional[float] = None,\n",
    ") -> t.List[str]:\n",
    "    sc.tl.rank_genes_groups(\n",
    "        adata,\n",
    "        groupby=\"perturbation_name\",\n",
    "        reference=CONTROL,\n",
    "        rankby_abs=True,\n",
    "        n_genes=n_genes,\n",
    "        method=\"wilcoxon\",\n",
    "        key_added=key_added,\n",
    "    )\n",
    "    markers = sc.get.rank_genes_groups_df(\n",
    "        adata, pert, key=key_added, pval_cutoff=alpha, log2fc_min=log2fc_min\n",
    "    )\n",
    "    logging.warning(f\"#pert markers: `{len(markers)}/{n_genes}`\")\n",
    "\n",
    "    return list(markers[\"names\"])\n",
    "\n",
    "\n",
    "def _subset_genes(\n",
    "    ds: du.Dataset, n_genes: int, markers: t.Optional[t.Sequence[str]]\n",
    ") -> du.Dataset:\n",
    "    test_adata = ds.adata_trn_x.concatenate(ds.adata_trn_y)  # combine trn ctrl/pert\n",
    "    if n_genes > 0:\n",
    "        sc.pp.highly_variable_genes(test_adata, n_top_genes=n_genes, subset=True)\n",
    "        var_names = test_adata.var_names\n",
    "        if markers is not None:\n",
    "            var_names = list(set(var_names) | set(markers))\n",
    "        LOGGER.warning(f\"Using `{len(var_names)}` HVGs\")\n",
    "    else:  # remove genes with constant expression\n",
    "        expressed = (test_adata.X > 0).sum(0).A.squeeze() > 0  # (g,)\n",
    "        var_names = test_adata.var_names[np.where(expressed)]\n",
    "        LOGGER.warning(f\"Using `{len(var_names)}` genes\")\n",
    "\n",
    "    return ds.subset_genes(var_names)\n",
    "\n",
    "\n",
    "def _subset_markers(\n",
    "    ds: du.Dataset, *markerss: t.Sequence[str]\n",
    ") -> t.Iterator[t.Sequence[str]]:\n",
    "    for markers in markerss:\n",
    "        markers = np.asarray(markers)\n",
    "        yield markers[np.isin(markers, ds.adata.var_names)]\n",
    "\n",
    "\n",
    "def _cost_fns(\n",
    "    gammas: t.Sequence[float],\n",
    "    k: t.Optional[int] = None,\n",
    ") -> t.Dict[str, t.Union[costs.SqEuclidean, sparse_costs.RegTICost]]:\n",
    "    fns = {\"sqeucl\": costs.SqEuclidean()}\n",
    "    names = (\"elastic\", \"stvs\") if k is None else (\"elastic\", \"stvs\", f\"kov-{k}\")\n",
    "    for name in names:\n",
    "        for gamma in gammas:\n",
    "            if name == \"elastic\":\n",
    "                cost_fn = sparse_costs.ElasticNet(gam=gamma, lam=0.0)\n",
    "            elif name == \"stvs\":\n",
    "                cost_fn = sparse_costs.ElasticSTVS(gam=gamma)\n",
    "            elif name == f\"kov-{k}\":\n",
    "                cost_fn = sparse_costs.ElasticSqKOverlap(k=k, gam=gamma)\n",
    "            else:\n",
    "                raise NotImplemented(name)\n",
    "            fns[f\"{name}-{gamma}\"] = cost_fn\n",
    "\n",
    "    return fns\n",
    "\n",
    "\n",
    "def _run(\n",
    "    adata: ad.AnnData,\n",
    "    args: argparse.Namespace,\n",
    "    *,\n",
    "    pert_markers: t.Sequence[str],\n",
    "    hvgs: t.Sequence[str],\n",
    ") -> t.List[t.Dict[str, float]]:\n",
    "    trn_cost_fns = _cost_fns([args.gamma], k=args.k)\n",
    "    tst_cost_fns = _cost_fns(\n",
    "        [args.gamma] if args.tst_gammas is None else args.tst_gammas, k=args.k\n",
    "    )\n",
    "    res = []\n",
    "\n",
    "    for ds in tqdm(\n",
    "        du.train_val_split(\n",
    "            adata,\n",
    "            ctrl=CONTROL,\n",
    "            pert=args.drug,\n",
    "            n_splits=args.n_folds,\n",
    "            test_size=args.test_size,\n",
    "            seed=args.seed,\n",
    "        ),\n",
    "        total=args.n_folds,\n",
    "    ):\n",
    "        ds = _subset_genes(\n",
    "            ds,\n",
    "            args.n_hvgs,\n",
    "            markers=pert_markers if args.ensure_markers_present else None,\n",
    "        )\n",
    "        pert_markers, *_ = _subset_markers(ds, pert_markers)\n",
    "        logging.warning(f\"#pert markers after gene subset: `{len(pert_markers)}`\")\n",
    "\n",
    "        ds_pca = ds.pca(n_pcs=args.n_pcs)\n",
    "        pca_potentials = None\n",
    "\n",
    "        tmp = {}\n",
    "        for trn_name, trn_cost_fn in trn_cost_fns.items():\n",
    "            batch_size = 1024 if trn_name == \"sqeucl\" else 4\n",
    "            epsilon, epsilon_stats = du.find_trn_epsilon(\n",
    "                ds, cost_fn=trn_cost_fn, fracs=args.trn_fracs, batch_size=batch_size\n",
    "            )\n",
    "            tmp[f\"{trn_name}_epsilon\"] = epsilon\n",
    "            tmp[f\"{trn_name}_epsilon-metric\"] = epsilon_stats\n",
    "\n",
    "            out, potentials = du.solve(\n",
    "                ds, cost_fn=trn_cost_fn, epsilon=epsilon, batch_size=batch_size\n",
    "            )\n",
    "            if trn_name == \"sqeucl\":\n",
    "                # for PCA metric\n",
    "                pca_epsilon, pca_epsilon_stats = du.find_trn_epsilon(\n",
    "                    ds_pca,\n",
    "                    cost_fn=trn_cost_fn,\n",
    "                    fracs=args.trn_fracs,\n",
    "                    batch_size=batch_size,\n",
    "                )\n",
    "                tmp[f\"{trn_name}_pca-epsilon\"] = pca_epsilon\n",
    "                tmp[f\"{trn_name}_pca-epsilon-metric\"] = pca_epsilon_stats\n",
    "                _, pca_potentials = du.solve(\n",
    "                    ds_pca,\n",
    "                    cost_fn=costs.SqEuclidean(),\n",
    "                    epsilon=pca_epsilon,\n",
    "                    batch_size=batch_size,\n",
    "                )\n",
    "\n",
    "            for fwd in [True, False]:\n",
    "                data_hat, perc_close, perc_neg, min_neg = du.predict(\n",
    "                    ds, potentials, forward=fwd, batch_size=4, nan_to_num=0.0\n",
    "                )\n",
    "                # metadata\n",
    "                tmp[f\"{trn_name}_%close_{fwd}\"] = perc_close\n",
    "                tmp[f\"{trn_name}_%neg_{fwd}\"] = perc_neg\n",
    "                tmp[f\"{trn_name}_min-neg_{fwd}\"] = min_neg\n",
    "                data_hat = jnp.clip(data_hat, 0.0, None)\n",
    "\n",
    "                # PCA metric: down-project and solve in sqeucl.\n",
    "                data_proj = (ds.tst_y if fwd else ds.tst_x) @ ds_pca.evecs\n",
    "                data_hat_proj = data_hat @ ds_pca.evecs\n",
    "                tmp[f\"{trn_name}_pca-proj-div_{fwd}\"] = du.solve_sink_div(\n",
    "                    data_proj,\n",
    "                    data_hat_proj,\n",
    "                    frac=MEAN_COST_FRAC,\n",
    "                    cost_fn=costs.SqEuclidean(),\n",
    "                    batch_size=batch_size,\n",
    "                )\n",
    "\n",
    "                pca_hat_raw, pca_hat, *_ = du.predict(\n",
    "                    ds_pca,\n",
    "                    pca_potentials,\n",
    "                    forward=fwd,\n",
    "                    batch_size=batch_size,\n",
    "                )\n",
    "                # compute sink-div in PCA/up-projected PCA space\n",
    "                pca_div, pca_div_raw = du.pca_metric(\n",
    "                    ds,\n",
    "                    ds_pca,\n",
    "                    data_hat=pca_hat,\n",
    "                    data_hat_raw=pca_hat_raw,\n",
    "                    frac=MEAN_COST_FRAC,\n",
    "                    cost_fn=trn_cost_fn,\n",
    "                    batch_size=batch_size,\n",
    "                    forward=fwd,\n",
    "                )\n",
    "                tmp[f\"{trn_name}_pca-div_{fwd}\"] = pca_div\n",
    "                tmp[f\"{trn_name}_pca-uproj-div_{fwd}\"] = pca_div_raw\n",
    "\n",
    "                # correlation\n",
    "                for k, v in du.feature_correlation(ds, data_hat, forward=fwd).items():\n",
    "                    tmp[f\"{trn_name}_{k}_{fwd}\"] = v\n",
    "\n",
    "                for tst_name, tst_cost_fn in tst_cost_fns.items():\n",
    "                    tst_batch_size = 1024 if tst_name == \"sqeucl\" else 4\n",
    "                    epsilons = du.compute_epsilons(\n",
    "                        ds,\n",
    "                        data_hat,\n",
    "                        tst_cost_fn,\n",
    "                        forward=fwd,\n",
    "                        fracs=[MEAN_COST_FRAC],\n",
    "                        batch_size=tst_batch_size,\n",
    "                    )\n",
    "                    for ix, epsilon in enumerate(epsilons):\n",
    "                        # Sinkhorn divergence/primal cost metric on all genes\n",
    "                        primal_cost, sink_div, _ = du.evaluate(\n",
    "                            ds,\n",
    "                            data_hat,\n",
    "                            forward=fwd,\n",
    "                            cost_fn=tst_cost_fn,\n",
    "                            epsilon=epsilon,\n",
    "                            batch_size=tst_batch_size,\n",
    "                        )\n",
    "                        tmp[f\"{trn_name}_{tst_name}-primal-{ix}_{fwd}\"] = primal_cost\n",
    "                        tmp[f\"{trn_name}_{tst_name}-div-{ix}_{fwd}\"] = sink_div\n",
    "                        tmp[f\"{trn_name}_{tst_name}-epsilon-{ix}_{fwd}\"] = epsilon\n",
    "\n",
    "                        if tst_name == \"sqeucl\":\n",
    "                            for kind, genes in zip(\n",
    "                                [\"markers\", \"hvgs\"], [pert_markers, hvgs]\n",
    "                            ):\n",
    "                                primal_cost, sink_div, n_common = du.evaluate(\n",
    "                                    ds,\n",
    "                                    data_hat,\n",
    "                                    forward=fwd,\n",
    "                                    cost_fn=costs.SqEuclidean(),\n",
    "                                    genes=genes,\n",
    "                                    epsilon=epsilon,\n",
    "                                )\n",
    "                                tmp[\n",
    "                                    f\"{trn_name}_{tst_name}-{kind}-primal-{ix}_{fwd}\"\n",
    "                                ] = primal_cost\n",
    "                                tmp[\n",
    "                                    f\"{trn_name}_{tst_name}-{kind}-div-{ix}_{fwd}\"\n",
    "                                ] = sink_div\n",
    "                                tmp[\n",
    "                                    f\"{trn_name}_{tst_name}-{kind}-common-{ix}_{fwd}\"\n",
    "                                ] = n_common\n",
    "\n",
    "                for kind, genes in zip([\"markers\", \"hvgs\"], [pert_markers, hvgs]):\n",
    "                    for k, v in du.gene_metric(\n",
    "                        ds, data_hat, forward=fwd, genes=genes\n",
    "                    ).items():\n",
    "                        tmp[f\"{trn_name}_{kind}-{k}_{fwd}\"] = v\n",
    "                    # R2 between average expression and log2fc\n",
    "                    for k, v in du.r2(ds, data_hat, forward=fwd, genes=genes).items():\n",
    "                        tmp[f\"{trn_name}_{kind}-{k}_{fwd}\"] = v\n",
    "                gc.collect()\n",
    "        res.append(tmp)\n",
    "    return res\n",
    "\n",
    "\n",
    "def main(args: argparse.Namespace) -> None:\n",
    "    save_dir = pathlib.Path(args.save_dir)\n",
    "    save_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    np.random.seed(args.seed)\n",
    "\n",
    "    adata = sc.read(args.data_path)\n",
    "    adata.var_names = adata.var_names.str.upper()\n",
    "\n",
    "    bdata = adata[adata.obs[\"perturbation_name\"].isin([CONTROL, args.drug])]\n",
    "    if args.dose is not None:\n",
    "        bdata = bdata[bdata.obs[\"dose_character\"].isin([\"0\", args.dose])]\n",
    "    bdata = bdata[bdata.obs[\"cell_type\"] == args.cell_line].copy()\n",
    "    assert bdata.n_obs, \"No cells have been selected.\"\n",
    "\n",
    "    sc.pp.highly_variable_genes(bdata, n_top_genes=args.n_hvgs_eval)\n",
    "    hvgs = list(bdata.var_names[bdata.var[\"highly_variable\"]])\n",
    "    logging.warning(f\"Using `{len(hvgs)}` HVGs for metrics\")\n",
    "\n",
    "    # compute the markers on the trn/tst data\n",
    "    pert_markers = _compute_markers(\n",
    "        bdata,\n",
    "        pert=args.drug,\n",
    "        n_genes=args.n_degs,\n",
    "        key_added=\"markers_small\",\n",
    "    )\n",
    "\n",
    "    LOGGER.warning(\n",
    "        f\"Running for cell line `{args.cell_line}`, dose `{args.dose}` with data shape `{bdata.shape}`, \"\n",
    "        f\"`{len(pert_markers)}` perturbation markers and `{len(hvgs)}` HVGs for evaluation\"\n",
    "    )\n",
    "    tick = time.perf_counter()\n",
    "    metrics = _run(bdata, args, pert_markers=pert_markers, hvgs=hvgs)\n",
    "    LOGGER.warning(f\"Done in `{time.perf_counter() - tick}s`\")\n",
    "\n",
    "    fname = (\n",
    "        save_dir / f\"result_{args.drug}_{args.cell_line}_{args.dose}_{args.gamma}.pkl\"\n",
    "    )\n",
    "    with open(fname, \"wb\") as fin:\n",
    "        pickle.dump(metrics, fin)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moscot_rev_new",
   "language": "python",
   "name": "moscot_rev_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
